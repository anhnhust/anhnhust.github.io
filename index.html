<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hoang Anh Nguyen - Embedded AI Engineer</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.6;
            color: #2c3e50;
            background-color: #f8f9fa;
            font-size: 16px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
            min-height: 100vh;
        }

        header {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .profile-section {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 40px;
            margin-bottom: 30px;
        }

        .profile-img {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: 4px solid white;
            background: linear-gradient(135deg, #34495e, #2c3e50);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 36px;
            color: white;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
        }

        .profile-img.has-image {
            background-image: url('your-photo.jpg');
        }

        .profile-info h1 {
            font-size: 2.8rem;
            margin-bottom: 10px;
            font-weight: 300;
            letter-spacing: 1px;
        }

        .profile-info .title {
            font-size: 1.3rem;
            opacity: 0.9;
            font-weight: 300;
            margin-bottom: 20px;
            font-style: italic;
        }

        .contact-info {
            display: flex;
            justify-content: center;
            gap: 30px;
            flex-wrap: wrap;
        }

        .contact-info a {
            color: white;
            text-decoration: none;
            padding: 8px 16px;
            border: 1px solid rgba(255,255,255,0.3);
            border-radius: 4px;
            transition: all 0.3s ease;
            font-size: 0.95rem;
        }

        .contact-info a:hover {
            background: rgba(255,255,255,0.1);
            border-color: rgba(255,255,255,0.5);
        }

        .main-content {
            padding: 40px;
        }

        .section {
            margin-bottom: 50px;
            border-bottom: 1px solid #e9ecef;
            padding-bottom: 40px;
        }

        .section:last-child {
            border-bottom: none;
        }

        .section h2 {
            color: #1e3c72;
            margin-bottom: 30px;
            font-size: 1.8rem;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 2px;
            position: relative;
            padding-bottom: 10px;
        }

        .section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 60px;
            height: 2px;
            background: #1e3c72;
        }

        .about-text {
            font-size: 1.1rem;
            line-height: 1.8;
            text-align: justify;
            color: #34495e;
            margin-bottom: 20px;
        }

        .education-item {
            background: #f8f9fa;
            padding: 25px;
            border-left: 4px solid #1e3c72;
            margin-bottom: 20px;
        }

        .education-item h3 {
            color: #1e3c72;
            font-size: 1.3rem;
            margin-bottom: 8px;
            font-weight: 500;
        }

        .education-item .degree {
            font-size: 1.1rem;
            color: #2c3e50;
            margin-bottom: 5px;
        }

        .education-item .date {
            color: #7f8c8d;
            font-style: italic;
            margin-bottom: 10px;
        }

        .education-item .achievement {
            color: #27ae60;
            font-weight: 500;
        }

        .experience-item {
            margin-bottom: 35px;
            padding: 25px 0;
            border-bottom: 1px solid #ecf0f1;
        }

        .experience-item:last-child {
            border-bottom: none;
        }

        .experience-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 15px;
            flex-wrap: wrap;
            gap: 10px;
        }

        .experience-company {
            color: #1e3c72;
            font-size: 1.2rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .experience-date {
            color: #7f8c8d;
            font-style: italic;
            font-size: 0.95rem;
        }

        .experience-title {
            color: #2c3e50;
            font-size: 1.1rem;
            font-weight: 500;
            margin-bottom: 15px;
            padding-left: 15px;
            border-left: 3px solid #3498db;
        }

        .experience-item ul {
            list-style: none;
            padding-left: 20px;
        }

        .experience-item li {
            position: relative;
            margin-bottom: 8px;
            padding-left: 20px;
            line-height: 1.6;
            color: #34495e;
        }

        .experience-item li::before {
            content: 'â€¢';
            position: absolute;
            left: 0;
            color: #3498db;
            font-weight: bold;
            font-size: 1.2rem;
        }

        .skills-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 25px;
        }

        .skill-category {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-top: 4px solid #1e3c72;
        }

        .skill-category h3 {
            color: #1e3c72;
            font-size: 1.2rem;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .skill-category p {
            color: #34495e;
            line-height: 1.6;
        }

        .publications-list {
            display: flex;
            flex-direction: column;
            gap: 25px;
        }

        .publication-item {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #27ae60;
        }

        .publication-title {
            color: #1e3c72;
            font-size: 1.1rem;
            font-weight: 500;
            margin-bottom: 10px;
            line-height: 1.4;
        }

        .publication-title a {
            color: inherit;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .publication-title a:hover {
            color: #3498db;
            text-decoration: underline;
        }

        .publication-venue {
            color: #7f8c8d;
            font-style: italic;
            line-height: 1.4;
        }

        .awards-list {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .award-item {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 20px;
            border-radius: 4px;
            color: #856404;
            font-weight: 500;
        }

        .languages-section {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #17a2b8;
        }

        .language-item {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .language-flag {
            font-size: 1.5rem;
        }

        .language-info strong {
            color: #1e3c72;
            font-size: 1.1rem;
        }

        .language-level {
            color: #7f8c8d;
            margin-top: 5px;
        }

        footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 30px 40px;
            font-size: 0.95rem;
        }

        footer p {
            margin-bottom: 10px;
            opacity: 0.9;
        }

        .footer-quote {
            font-style: italic;
            opacity: 0.7;
            border-top: 1px solid rgba(255,255,255,0.2);
            padding-top: 15px;
            margin-top: 15px;
        }

        @media (max-width: 768px) {
            .profile-section {
                flex-direction: column;
                gap: 20px;
            }

            .profile-info h1 {
                font-size: 2.2rem;
            }

            .main-content {
                padding: 30px 20px;
            }

            .experience-header {
                flex-direction: column;
                align-items: flex-start;
            }

            .contact-info {
                gap: 15px;
            }

            .contact-info a {
                font-size: 0.9rem;
                padding: 6px 12px;
            }

            .skills-container {
                grid-template-columns: 1fr;
            }
        }

        @media print {
            body {
                background: white;
            }
            
            .container {
                box-shadow: none;
            }
            
            header {
                background: #1e3c72 !important;
                -webkit-print-color-adjust: exact;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="profile-section">
                <div class="profile-img has-image">
                </div>
                <div class="profile-info">
                    <h1>Nguyen Hoang Anh</h1>
                    <p class="title">Embedded AI Engineer</p>
                </div>
            </div>
            <div class="contact-info">
                <a href="mailto:nguyenhoanganht3@gmail.com">nguyenhoanganht3@gmail.com</a>
                <a href="https://www.linkedin.com/in/anhhoang23/" target="_blank">LinkedIn Profile</a>
                <a href="tel:+84344723585">+84 344 723 585</a>
            </div>
        </header>

        <div class="main-content">
            <section class="section">
                <h2>Professional Summary</h2>
                <p class="about-text">
                    Experienced Embedded AI Engineer with comprehensive expertise in deploying deep learning models on edge devices. 
                    Proven track record of over three years in computer vision, person re-identification, and TinyML applications, 
                    with specialization in optimizing AI models for resource-constrained environments. Demonstrated ability to bridge 
                    the gap between theoretical research and practical implementation in production systems.
                </p>
                <p class="about-text">
                    Currently focused on advancing action recognition and vision-language model deployment on edge devices, 
                    utilizing state-of-the-art technologies including NVIDIA DeepStream, TensorRT, and various model optimization 
                    methodologies. Committed to pushing the boundaries of efficient AI deployment in embedded systems.
                </p>
            </section>

            <section class="section">
                <h2>Education</h2>
                <div class="education-item">
                    <h3>Hanoi University of Science and Technology</h3>
                    <div class="degree">Bachelor of Engineering in Electronics and Telecommunications</div>
                    <div class="date">September 2019 â€“ February 2024</div>
                    <div class="achievement">Academic Achievement: Excellent Degree </div>
                </div>
            </section>

            <section class="section">
                <h2>Professional Experience</h2>
                
                <div class="experience-item">
                    <div class="experience-header">
                        <div class="experience-company">FPT Software</div>
                        <div class="experience-date">March 2024 â€“ Present</div>
                    </div>
                    
                    <div class="experience-title">AI-Based Action Recognition Systems</div>
                    <ul>
                        <li>Architected and implemented advanced action recognition systems utilizing computer vision techniques for real-time human activity classification from image and video inputs</li>
                        <li>Optimized deep learning model deployment on NVIDIA Jetson Orin Nano platforms using DeepStream SDK and TensorRT optimization framework, achieving significant improvements in inference speed and accuracy</li>
                        <li>Executed comprehensive end-to-end development lifecycle on Linux environments, encompassing algorithm design, API integration, and performance optimization for embedded system constraints</li>
                    </ul>

                    <div class="experience-title">Vision-Language Model Integration</div>
                    <ul>
                        <li>Developed and integrated state-of-the-art vision-language models including Qwen-VL, VILA, and Gemma into production Linux-based systems</li>
                        <li>Implemented advanced model quantization techniques utilizing TensorRT-LLM and llama.cpp frameworks to optimize computational efficiency for resource-constrained edge environments</li>
                        <li>Designed scalable orchestrator-worker architecture supporting multi-agent VLM workflows with comprehensive development lifecycle management</li>
                    </ul>
                </div>

                <div class="experience-item">
                    <div class="experience-header">
                        <div class="experience-company">VNPT Technology</div>
                        <div class="experience-date">August 2022 â€“ March 2024</div>
                    </div>
                    <div class="experience-title">Edge AI System Development</div>
                    <ul>
                        <li>Successfully deployed object detection and acoustic recognition models on edge camera systems in production environments, ensuring robust real-world performance</li>
                        <li>Conducted research and implementation of deep learning model compression techniques including quantization, pruning, and knowledge distillation methodologies</li>
                        <li>Executed model deployment across diverse embedded frameworks including NCNN, MNN, and Darknet, optimizing for various hardware architectures</li>
                        <li>Pioneered TinyML implementation using TensorFlow Lite and Edge Impulse frameworks for ultra-lightweight machine learning deployment</li>
                        <li>Performed cross-compilation and optimization for diverse embedded architectures including MIPS and RISC-V processors</li>
                        <li>Achieved successful model deployment on severely resource-constrained devices with memory footprints ranging from 10KB to 600KB</li>
                    </ul>
                </div>

                <div class="experience-item">
                    <div class="experience-header">
                        <div class="experience-company">Computer Vision Laboratory</div>
                        <div class="experience-date">October 2021 â€“ May 2024</div>
                    </div>
                    <div class="experience-title">Research: Person Re-identification in Surveillance Networks</div>
                    <ul>
                        <li>Led comprehensive research initiative on "Person Re-identification in Surveillance Camera Systems" with focus on multi-camera tracking applications</li>
                        <li>Conducted systematic analysis and implementation of state-of-the-art person re-identification algorithms from international research literature</li>
                        <li>Implemented and evaluated advanced CNN architectures including VGG16, ResNet50, and Vision Transformer models for person re-identification tasks</li>
                        <li>Developed novel optimization algorithms for Earth Mover's Distance computation, achieving approximately 10% improvement over existing state-of-the-art methods</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <h2>Technical Expertise</h2>
                <div class="skills-container">
                    <div class="skill-category">
                        <h3>Programming & Development</h3>
                        <p>Python, C/C++, OpenCV, TensorFlow, PyTorch, TensorRT, ONNX Runtime, Triton Inference Server, NVIDIA DeepStream</p>
                    </div>
                    <div class="skill-category">
                        <h3>Embedded AI Frameworks</h3>
                        <p>TinyML, NCNN, MNN, TNN, TensorFlow Lite, Edge Impulse, Quantization Techniques, Model Compression</p>
                    </div>
                    <div class="skill-category">
                        <h3>Generative AI & LLMs</h3>
                        <p>Vision-Language Models, Large Language Models, TensorRT-LLM, llama.cpp, AWQ, GGUF, Qwen-VL, VILA, Gemma</p>
                    </div>
                    <div class="skill-category">
                        <h3>Hardware Platforms</h3>
                        <p>NVIDIA Jetson (Nano/Orin), Raspberry Pi, Orange Pi, Luckfox Pico, Microcontroller Systems, MIPS, RISC-V</p>
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Research Publications</h2>
                <div class="publications-list">
                    <div class="publication-item">
                        <div class="publication-title">
                            <a href="https://ieeexplore.ieee.org/document/9924686" target="_blank">
                                Exploiting Matching Local Information for Person Re-Identification
                            </a>
                        </div>
                        <div class="publication-venue">
                            2022 International Conference on Multimedia Analysis and Pattern Recognition (MAPR), IEEE
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="publication-title">
                            <a href="https://www.sciencedirect.com/science/article/pii/S2666827025000465" target="_blank">
                                EMD-based Local Matching for Occluded Person Re-Identification
                            </a>
                        </div>
                        <div class="publication-venue">
                            Machine Learning with Applications, Elsevier, Volume 20, June 2025, Article ID: 100663
                        </div>
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Awards & Recognition</h2>
                <div class="awards-list">
                    <div class="award-item">
                        Outstanding Graduation Project Award - Highest absolute score, School of Electrical and Electronic Engineering, HUST (2024)
                    </div>
                    <div class="award-item">
                        First Prize - University Creativity and Entrepreneurship Competition, HUST (2023)
                    </div>
                    <div class="award-item">
                        Third Prize - Research Science Student Competition, School of Electrical Engineering, HUST (2023)
                    </div>
                    <div class="award-item">
                        Academic Excellence Award - Top 2 students selected for exchange program at Shibaura Institute of Technology, Japan
                    </div>
                    <div class="award-item">
                        Panasonic Scholarship - Top 20 recipients nationwide, Vietnam (2023)
                    </div>
                    <div class="award-item">
                        Lawrence S. Ting Scholarship for Academic Excellence (3 consecutive awards)
                    </div>
                    <div class="award-item">
                        Excellence in Academic Performance Scholarship, HUST (5 consecutive awards)
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Languages</h2>
                <div class="languages-section">
                    <div class="language-item">
                        <span class="language-flag">ðŸ‡ºðŸ‡¸</span>
                        <div class="language-info">
                            <div><strong>English</strong> - Professional Working Proficiency</div>
                            <div class="language-level">Technical communication and documentation (Equivalent to IELTS 5.5)</div>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <footer>
            <p>&copy; 2024 Nguyen Hoang Anh | Embedded AI Engineer</p>
            <div class="footer-quote">
                "Advancing the frontier of artificial intelligence through innovative embedded system solutions"
            </div>
        </footer>
    </div>
</body>
</html>
